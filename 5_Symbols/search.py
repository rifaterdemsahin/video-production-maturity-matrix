#!/usr/bin/env python3
"""
ğŸ” Semantic Search CLI
Search across all Video Production Maturity Matrix documents
using natural language queries.

Usage:
    python search.py "how to improve thumbnail CTR"
    python search.py "editing workflow DaVinci" --top 10
"""

import os
import sys
import argparse
import requests

# â”€â”€ CONFIG â”€â”€
OLLAMA_URL = os.getenv("OLLAMA_HOST", "http://localhost:11434")
QDRANT_URL = os.getenv("QDRANT_HOST", "http://localhost:6333")
COLLECTION = os.getenv("QDRANT_COLLECTION", "video_maturity")
MODEL = os.getenv("OLLAMA_MODEL", "nomic-embed-text")

STAGE_LABELS = {
    "1_Real_Unknown": "â“ Stage 1: Real Unknown",
    "2_Environment":  "ğŸŒ Stage 2: Environment",
    "3_Simulation":   "ğŸ¨ Stage 3: Simulation",
    "4_Formula":      "ğŸ“ Stage 4: Formula",
    "5_Symbols":      "ğŸ’» Stage 5: Symbols",
    "6_Semblance":    "ğŸ› Stage 6: Semblance",
    "7_Testing_Known":"âœ… Stage 7: Testing",
    "root":           "ğŸ“ Root",
}


def get_embedding(text: str) -> list:
    response = requests.post(
        f"{OLLAMA_URL}/api/embeddings",
        json={"model": MODEL, "prompt": text},
        timeout=30
    )
    response.raise_for_status()
    return response.json()["embedding"]


def search(query: str, top_k: int = 5) -> list:
    query_vector = get_embedding(query)
    resp = requests.post(
        f"{QDRANT_URL}/collections/{COLLECTION}/points/search",
        json={"vector": query_vector, "limit": top_k, "with_payload": True}
    )
    resp.raise_for_status()
    return resp.json()["result"]


def main():
    parser = argparse.ArgumentParser(description="Semantic search over maturity docs")
    parser.add_argument("query", nargs="?", help="Search query")
    parser.add_argument("--top", "-n", type=int, default=5, help="Number of results")
    args = parser.parse_args()

    query = args.query or input("ğŸ” Enter search query: ").strip()
    if not query:
        print("âŒ No query provided.")
        sys.exit(1)

    print(f"\nğŸ” Searching: \"{query}\"\n" + "â”€" * 50)

    try:
        results = search(query, args.top)
    except requests.exceptions.ConnectionError:
        print("âŒ Cannot connect to Ollama or Qdrant.")
        print("   Run: docker compose up -d && ollama serve")
        sys.exit(1)

    if not results:
        print("No results found. Run indexer.py first.")
        return

    for i, r in enumerate(results, 1):
        p = r["payload"]
        stage = STAGE_LABELS.get(p.get("stage", "root"), p.get("stage", ""))
        score = r["score"]
        bar = "â–ˆ" * int(score * 20) + "â–‘" * (20 - int(score * 20))
        print(f"\n{i}. [{bar}] {score:.3f}")
        print(f"   {stage}")
        print(f"   ğŸ“„ {p['path']}")
        print(f"   ğŸ“Œ {p['title']}")
        if p.get("preview"):
            preview = p["preview"][:120].replace("\n", " ").strip()
            print(f"   ğŸ’¬ {preview}...")


if __name__ == "__main__":
    main()
